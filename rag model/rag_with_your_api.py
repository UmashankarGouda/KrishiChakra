"""
RAG System using YOUR API for embeddings
No need for sentence-transformers!
"""

from openai import OpenAI
import chromadb
import os

# ============================================================================
# CONFIGURATION
# ============================================================================
API_KEY = "ddc-a4f-af21ceb75c0a47d4afb3b4f5d0dd5804"
BASE_URL = "https://api.a4f.co/v1"
EMBEDDING_MODEL = "provider-6/qwen3-embedding-4b"  # Your embedding model!
CHAT_MODEL = "provider-3/deepseek-v3"

# ============================================================================
# STEP 1: CREATE EMBEDDINGS USING YOUR API
# ============================================================================

def create_embedding(text):
    """Create embedding using YOUR API (not local model!)"""
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    
    response = client.embeddings.create(
        model=EMBEDDING_MODEL,
        input=text
    )
    
    return response.data[0].embedding

# Test it
print("="*70)
print("ğŸ§® TESTING EMBEDDING CREATION WITH YOUR API")
print("="*70)

test_text = "Rice-wheat crop rotation improves soil health"
print(f"\nğŸ“ Input: '{test_text}'")
print(f"ğŸ”— Using API: {BASE_URL}")
print(f"ğŸ¤– Model: {EMBEDDING_MODEL}")

try:
    embedding = create_embedding(test_text)
    print(f"\nâœ… SUCCESS!")
    print(f"ğŸ“Š Embedding generated: {len(embedding)} dimensions")
    print(f"ğŸ“ˆ Sample values: {embedding[:5]}...")
except Exception as e:
    print(f"\nâŒ Error: {e}")

# ============================================================================
# STEP 2: CHROMADB - LOCAL STORAGE
# ============================================================================

print("\n\n" + "="*70)
print("ğŸ—„ï¸ CHROMADB - LOCAL STORAGE LOCATION")
print("="*70)

# Initialize ChromaDB (stores locally)
chroma_client = chromadb.PersistentClient(path="./chroma_db")

print(f"\nğŸ“‚ Database Location: ./chroma_db/")
print(f"   (This folder will be created in your project directory)")

# Create collection
collection = chroma_client.get_or_create_collection(
    name="crop_rotation_docs"
)

print(f"\nâœ… Collection created: 'crop_rotation_docs'")
print(f"ğŸ“Š Current documents in collection: {collection.count()}")

# ============================================================================
# STEP 3: DEMONSTRATE ADDING DOCUMENTS
# ============================================================================

print("\n\n" + "="*70)
print("ğŸ“š ADDING SAMPLE DOCUMENTS TO LOCAL DATABASE")
print("="*70)

sample_docs = [
    "Rice-wheat rotation increases yield by 20% in Punjab",
    "Legume crops improve soil nitrogen for subsequent wheat",
    "Crop rotation reduces pest pressure and disease"
]

print(f"\nğŸ“ Adding {len(sample_docs)} sample documents...")

for i, doc in enumerate(sample_docs):
    try:
        # Create embedding using YOUR API
        embedding = create_embedding(doc)
        
        # Store in ChromaDB (locally)
        collection.add(
            documents=[doc],
            embeddings=[embedding],
            ids=[f"sample_doc_{i}"]
        )
        print(f"  âœ… Doc {i+1}: {doc[:50]}...")
    except Exception as e:
        print(f"  âŒ Error: {e}")

print(f"\nğŸ“Š Total documents now: {collection.count()}")

# ============================================================================
# STEP 4: QUERY THE DATABASE
# ============================================================================

print("\n\n" + "="*70)
print("ğŸ” QUERYING THE LOCAL DATABASE")
print("="*70)

query = "How to improve wheat yields?"
print(f"\nâ“ Question: '{query}'")

try:
    # Create embedding for query
    query_embedding = create_embedding(query)
    
    # Search ChromaDB (local database)
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=2
    )
    
    print(f"\nâœ… Found {len(results['documents'][0])} relevant documents:\n")
    for i, doc in enumerate(results['documents'][0], 1):
        print(f"{i}. {doc}")

except Exception as e:
    print(f"\nâŒ Error: {e}")

# ============================================================================
# STORAGE INFO
# ============================================================================

print("\n\n" + "="*70)
print("ğŸ’¾ WHERE IS EVERYTHING STORED?")
print("="*70)

print("""
ğŸ“‚ Your Project Folder
  â”‚
  â”œâ”€â”€ ğŸ“ cleaned/                  â† Your 30 cleaned documents
  â”‚   â”œâ”€â”€ AgroSense...txt
  â”‚   â”œâ”€â”€ AI-Enhanced...txt
  â”‚   â””â”€â”€ ...
  â”‚
  â”œâ”€â”€ ğŸ“ chroma_db/               â† LOCAL DATABASE (created automatically)
  â”‚   â”œâ”€â”€ chroma.sqlite3          â† Metadata
  â”‚   â””â”€â”€ [UUID folders]          â† Embeddings & data
  â”‚
  â””â”€â”€ ğŸ“„ rag_system.py            â† Your RAG code

ğŸ”‘ KEY POINTS:

1. âœ… Embeddings created via YOUR API (api.a4f.co)
   - Model: provider-6/qwen3-embedding-4b
   - No local model needed!

2. âœ… ChromaDB stores LOCALLY in ./chroma_db/
   - Free
   - Fast
   - Private
   - No internet needed after setup

3. âœ… Process:
   Step 1: Read cleaned document
   Step 2: Send to API â†’ Get embedding (array of numbers)
   Step 3: Save to ChromaDB (local folder)
   Step 4: Repeat for all 30 documents
   
   Later when querying:
   Step 1: User asks question
   Step 2: Convert question to embedding (via API)
   Step 3: Search ChromaDB (local, instant)
   Step 4: Send results to LLM for answer

4. âœ… Database Size:
   - 30 documents Ã— ~200 chunks = ~6,000 chunks
   - Each chunk = ~1KB text + 4KB embedding
   - Total: ~30MB local storage (tiny!)
""")

print("\n" + "="*70)
print("ğŸ¯ SUMMARY:")
print("="*70)
print("""
âœ… Embeddings: YOUR API (provider-6/qwen3-embedding-4b)
âœ… Storage: LOCAL ChromaDB (./chroma_db/ folder)
âœ… Cost: FREE (local storage)
âœ… Privacy: 100% (never leaves your computer after setup)

Ready to build the full system? ğŸš€
""")
